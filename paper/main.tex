% TEMPLATE for Usenix papers, specifically to meet requirements of
%  USENIX '05
% originally a template for producing IEEE-format articles using LaTeX.
%   written by Matthew Ward, CS Department, Worcester Polytechnic Institute.
% adapted by David Beazley for his excellent SWIG paper in Proceedings,
%   Tcl 96
% turned into a smartass generic template by De Clarke, with thanks to
%   both the above pioneers
% use at your own risk.  Complaints to /dev/null.
% make it two column with no page numbering, default is 10 point

% Munged by Fred Douglis <douglis@research.att.com> 10/97 to separate
% the .sty file from the LaTeX source template, so that people can
% more easily include the .sty file into an existing document.  Also
% changed to more closely follow the style guidelines as represented
% by the Word sample file. 

% Note that since 2010, USENIX does not require endnotes. If you want
% foot of page notes, don't include the endnotes package in the 
% usepackage command, below.


% This version uses the latex2e styles, not the very ancient 2.09 stuff.
\documentclass[letterpaper,twocolumn,10pt]{article}
\usepackage{usenix,epsfig,endnotes,url, graphicx}
\graphicspath{{figures/}}
\begin{document}

%don't want date printed
\date{}

%make title bold and 14 pt font (Latex default is non-bold, 16 pt)
\title{\Large \bf Traffic Sign Classification}

\author{
	%for single author (just remove % characters)
	{\rm Colin Howes}\\
	University of Waterloo
} % end author

\maketitle

\thispagestyle{empty}


\subsection*{Abstract}

Efficient and accurate classification of traffic signs constitutes an interesting computer vision problem with a high degree of real-world relevance. Traffic sign recognition is necessary for the development of autonomous vehicles and driver assistance systems, which must be able to correctly detect and classify traffic signs in real-time under varying conditions. As such, traffic sign classification has enjoyed significant recent attention, and current techniques are able to meet or surpass human performance in publicly available data sets. Here, I compare successful approaches to traffic sign classification and present the performance of a traffic sign classifier based on a convolutional neural network.


\section{Introduction}

Traffic sign classification is a computer vision problem with a great deal of relevance to current advancements in autonomous vehicles and driver assistance systems. A viable traffic sign classifier must not only detect and categorize signs with a high degree of accuracy, it must perform efficiently, tolerate potentially noisy environments, and perform correctly in the presence of defects or variations in sign appearance \cite{stallkamp_german_2011, stallkamp_man_2012}. 

While many techniques have been applied to address the traffic sign classification problem, here I focus on a representative subset of state-of-the-art techniques that exhibit near-human performance in empirical testing: linear discriminant analysis, support vector machines, convolutional neural networks, and committees made up of multiple classifiers.

\section{Benchmarks}

The techniques discussed here were selected from high performing approaches entered into the German Traffic Sign Recognition Benchmark (GTSRB) competition, or developed and tested on this dataset after the conclusion of the competition \cite{stallkamp_german_2011, stallkamp_man_2012}. This competition provides a high quality data set of traffic sign images split into training and test sets that can be used to design, validate, and compare approaches to traffic sign classification. The data set consists of 34799 training images and 12630 test images comprised of 43 classes. The data set is unbalanced, with class representation ranging from 0.5 \% and 5.5 \% of images \cite{stallkamp_german_2011}.

The German Traffic Sign Recognition Benchmark was originally formulated as a competition in two stages. Following the completion of the final stage, the GTSRB data set was made available online as a public benchmark to drive the development and empirical analysis of new classification algorithms \cite{stallkamp_german_2011, stallkamp_man_2012}. Here, I discuss the performance of classifiers entered at each stage of the competition, as well as other classifiers developed following the conclusion of the competition that provide an analysis based on the GTSRB data set.\footnote{It is worth noting that all of the published classifiers developed after 2012 that I have found as of this writing have provided an analysis using the GTSRB data set, so limiting discussion to approaches using this benchmark does not limit the scope of this paper.} 

\section{Comparison of Techniques}

\subsection{Features}

Traffic signs are designed to be easy for humans to detect and recognize quickly. In order to accomplish this, signs tend to be made up of distinct shapes, have high contrast lettering or pictograms, and strong colouration for high-importance sign classes (e.g.\ stop signs). The techniques discussed here make use of different feature sets to drive training and classification. 

While contrast and colour are fairly easy to define based on RBG and greyscale pixel values, other features are more difficult to represent. In particular, histograms of oriented gradient (HOG) are commonly used by image classification algorithms as a means of determining shape and orientation information. Briefly, the orientation of pixel values across image subregions are computed and combined hierarchically to produce feature vectors representing geometric information about an image \cite{stallkamp_german_2011, stallkamp_man_2012}. A number of other features were preprocessed and made available along with the GTSRB data set, but they were not used in any of the classifiers compared here, so they are not discussed.


\subsection{Linear Discriminant Analysis}

Linear discriminant analysis (LDA) ...
% TODO: What is LDA, how does it work, etc.

% TODO: How is LDA applied to traffic sign classification, how does it perform, etc. 

\subsection{Support Vector Machines}

% TODO: SVMs


\subsection{Convolutional Neural Networks}

Convolutional neural networks (CNNs) ...
% What are CNNs, how do they work, etc.

% How are CNNs applied to traffic sign classification, examine different implementations, etc.

\subsection{Committees}

Multi-column deep neural networks (MCDNNs) ...
% What are MCDNNs, how do they work, etc. Note that they can involve the use of CNNs so there is some overlap

% How are they applied to traffic sign classification, performance, implementation, etc.

\subsection{Discussion}

In general, methods based on convolutional neural networks have been shown to offer extremely high accuracy, matching or even exceeding human performance \cite{ciresan_committee_2011, ciresan_multi-column_2012, sermanet_convolutional_2012, sermanet_traffic_2011}. This high accuracy comes at the expense of both training and classification time, with large networks requiring days to train. Additionally, access to high-end hardware is necessary in order to achieve real-time classification with a trained model, making it difficult to implement high performant CNNs in embedded hardware that may need to support other computationally expensive functionality such as lane detection \cite{ciresan_committee_2011, ciresan_multi-column_2012, lane-detection}.

Linear discriminant analysis and support vector machines offer a significant performance advantage over neural networks, but at the cost of some accuracy. Although both LDA and SVM based techniques boast higher than 95 \% accuracy, this may not be acceptable for real-world sitations where recognizing and reacting to a sign is critical for passenger safety \cite{}. Moreover, the designers of the GTSRB competition note that some of the human control participants found the interface used to gather human responses was uninituitive and difficult to use \cite{stallkamp_german_2011, stallkamp_man_2012}. As a result, human performance may have been artificially low due to testing conditions, while the nature of the constructed data set was likely advantagous to the classifiers since each test case has a well defined class with none of the ambiguity associated with real-world driving scenarios. Thus, implementations that fail to match human performance in an artificial environment are likely not good candidates for use in real autonomous vehicles or other safety-critical applications.

As hardware continues to become more powerful, computationally expensive classifiers based on committees of neural networks will likely become an even more attractive approach due to their robustness and accuracy. Indeed, advances in powerful, highly parallel embedded components, such as FPGA, are already seeing use in the automotive industry, are already being used in autonomous driving research \cite{fpga, fpga2}.

Finally, the emergence of ``standard'' benchmarks for traffic sign classification is something that bears consideration. The motivating idea behind benchmarks is that they give researchers and developers a way to assess how well a system performs. The consequence of this is that systems end up being tailored towards high performance on a benchmark rather than on the task they are designed to perform. In the context of machine learning, this could lead to overfitting, such that classifiers perform well on benchmarks but not on real-world examples.

One solution to this is to adopt many different benchmarks, and use classifiers that perform well on all of them. This is solution suits the traffic sign classification problem well, given that different regions have adopted different sets of traffic signs and classifiers need to be trained on data from every region where it is expected to be used. Indeed, a number of public data sets have been released since the GTSRB data set was made public, including the LISA (United States) and BelgiumTS (Belgium) data sets \cite{mathias_traffic_2013, mogelmose_vision-based_2012}. By benchmarking traffic sign classifiers on a diverse set of benchmarks will prevent overfitting and improve generalizability. 




\section{Methodology}

In order to validate previous results demonstrating the effectiveness of convolutional neural networks for traffic sign classification, I implemented a simple traffic sign classifier based on a convolutional neural network and evaluated it using the German Traffic Sign Detection Benchmark data set \cite{stallkamp_german_2011, stallkamp_man_2012}. 

\subsection{Architecture}

My approach was similar to the approaches outlined in \cite{sermanet_convolutional_2012, sermanet_traffic_2011}, though the architecture I present here used all colour channels and is purely feed-forward, with the classifier layer connecting only to the final convolutional layer. Similar models have shown high performance in previous replications, including \cite{keras_traffic} and \cite{tensorflow_traffic}, and the simplicity of this architecture makes it an attractive choice for experimentation.

The model is made up of three pairs of feed-forward convolutional layers seperated by $2 \times 2$ max-pooling layers. Each of these pooling layers feeds into a dropout layer which drops $1/4^{th}$ of its inputs. The final set of convolutional, pooling, and dropout layers are flattened and passed into a classifier layer, which feeds into a softmax output layer that returns a probability distribution over the classes for a given input. The prediction for a given input is simply the maximum over this probability distribution.

\subsection{Training}

I trained the models over 200 epochs using the default batch size of 32 and a learning rate of 0.001. I used categorical cross-entropy as the loss function and stochastic gradient descent as the optimizer, which is suggested for multi-label classification problems \cite{lasagne_loss}.

\section{Results}

When training with only unaltered images provided in the GTSRB data set, my model had an accuracy of 95.42 \% on the test set. This is reasonably high considering the simplicity of the model and lack of data set augmentation, though accuracy is considerably lower than both human performance (98.84 \%) and the performance of other classifiers implemented using CNNs (98.31 \%) \cite{sermanet_convolutional_2012, sermanet_traffic_2011, stallkamp_german_2011, stallkamp_man_2012}. Figure 1 and Figure 2 show the accuracy and loss of the network over 200 training epochs when trained only on unaugmented images provided in the GTSRB data set.

\begin{figure}
\includegraphics[width=3.25in]{accuracy}
\caption{Accuracy over 200 epochs on the base image set. Data for ``test'' instances are taken from performance on a validation set at the end of each epoch}
\end{figure}

\begin{figure}
\includegraphics[width=3.25in]{loss}
\caption{Loss over 200 epochs on the base image set. Data for ``test'' instances are taken from performance on a validation set at the end of each epoch}
\end{figure}

In order to assess the benefit of augmenting the data set with simple transformations of training images, I trained the model again on the same architecture, randomly applying a gaussian blur to half of the training examples. I observed a marginal improvement over the unaugmented data set, with the new model correctly classifying 96.00 \% of test images. Due to time limitations, it was not possible to experiment with other transformations, though I suspect that applying a random mix of transformations to generate the augmented data set would produce better results, since this technique has been used with considerable success in the past \cite{ciresan_committee_2011}. Figure 3 and Figure 4 show the accuracy and loss of the network over 200 training epochs when trained the augmented data set.

\begin{figure}
\includegraphics[width=3.25in]{accuracy}
\caption{Accuracy over 200 epochs using data augmentation. Data for ``test'' instances are taken from performance on a validation set at the end of each epoch}
\end{figure}

\begin{figure}
\includegraphics[width=3.25in]{loss}
\caption{Loss over 200 epochs using data augmentation. Data for ``test'' instances are taken from performance on a validation set at the end of each epoch}
\end{figure}


\section{Conclusions}


\section{Summary}

I presented an analysis and comparison of a set of traffic sign recognition techniques that performed well on a competition data set. In addition, I presented a simple implementation of a traffic sign classifier using a convolutional neural network and compared the effectiveness of this implementation with the performance of past techniques.


{\footnotesize \bibliographystyle{acm}
\bibliography{refs.bib}}

\end{document}
